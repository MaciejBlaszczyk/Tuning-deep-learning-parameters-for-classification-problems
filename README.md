# Tuning-deep-learning-parameters-for-classification-problems
The aim of this project is to test various types of deep neural networks with different hyperparameters in task of classification. Tested networks: MLP, CNN, Capsule network, LSTM network. Utilized 8 datasets from PMLB collection. Used techniques: grid search, 5-fold cross validation. NNs were also compared with XGBoost to check if ML algorithms are competitive with NNs. Auxiliary research problems: How many neurons in hidden layer for MLP? How many hidden layers for MLP? Tech stack: Python 3, Keras, Tensorflow, Numpy, Pandas, Matplotlib, Seaborn.
